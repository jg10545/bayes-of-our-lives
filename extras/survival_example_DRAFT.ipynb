{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# survival analysis example\n",
    "\n",
    "Let's use `stan` to code up a simple Bayesian Cox Proportional Hazards Model.\n",
    "\n",
    "## A couple general things about survival analysis\n",
    "\n",
    "The high-level problem we have is modeling \"how long til an event happens?\". Lots of obvious applications in medicine and insurance.\n",
    "\n",
    "* One important practical concept is \"censoring\"- a member of your dataset may have exited the study before an event happened. For example, in a medical study, somebody was still alive at the end of it, or someone got hit by a car before the disease killed them. So you don't know how long it was until the event happened, but you *do know* the time was greater than some number. Survival analysis models can generally handle a mix of uncensored and censored data.\n",
    "\n",
    "* If you're familiar with generalized linear models, then this might just sound like a GLM with an exponential link function. Under such a model, *conditioned on the covariates* the event would have a constant probability per time of occurring. Survival models frequently use the *Weibull distribution*, which looks sort of like an exponential with an additional \"shape parameter\" $k$.\n",
    "\n",
    "  * if $k = 1$, the Weibull reduces to an exponential\n",
    "  * if $k > 1$, then all other things being equal the event probability per time tends to increase over time (think probability of dying from cancer or an aging industrial component failing)\n",
    "  * kf $k < 1$, then all other things being equal the event probability per time tends to decrease (such as an industrial component failing due to defects)\n",
    "\n",
    "## A couple general thoughts about this notebook/approach\n",
    "\n",
    "* I'm using a gamma prior over the Weibull shape parameter. Note that `stan` and `numpy` parameterize this distribution differently.\n",
    "* The closest examples I found in `stan`used the `target +=` syntax. `target` isn't exactly a variable but in some cases acts like one- you basically use it as an accumulator for the log likelihood.\n",
    "* There are some high-level software packages (`stan`-based and otherwise) for survival analysis; it might be worth investigating some of them if we want to start using these more seriously.\n",
    "\n",
    "## Data\n",
    "\n",
    "I wanted a small-ish multivariate survival dataset with both censored and uncensored data. I've been using the VA lung cancer dataset posted here: http://www.stat.rice.edu/~sneeley/STAT553/Datasets/survivaldata.txt \n",
    "\n",
    ">VA lung cancer data \n",
    ">\n",
    ">Patients with advanced, inoperable lung cancer were treated with chemotherapy. \n",
    ">\n",
    ">N = 137 \n",
    ">\n",
    "> Veteran's Administration Lung Cancer Trial \n",
    ">\n",
    "> Taken from Kalbfleisch and Prentice, pages 223-224  \n",
    ">\n",
    "\n",
    "### Variables\n",
    "* Treatment 1=standard, 2=test \n",
    "* Cell type 1=squamous, 2=small cell, 3=adeno, 4=large \n",
    "* Survival in days \n",
    "* Status 1=dead, 0=censored \n",
    "* Karnofsky score (measure of general performance, 100=best) \n",
    "* Months from Diagnosis \n",
    "* Age in years \n",
    "* Prior therapy 0=no, 10=yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pystan\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and EDA\n",
    "\n",
    "Let's take a look at some of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lungcancer.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = pd.get_dummies(df.celltype)\n",
    "celltype.columns = [\"squamous\", \"small cell\", \"adeno\", \"large\"]\n",
    "celltype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.treatment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.celltype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# censoring\n",
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.prior_therapy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.age_yrs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.survival_days);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.karnofsky);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(df.months_from_diagnosis));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values=\"survival_days\", index=[\"treatment\", \"status\"], aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [1,2,3,4]:\n",
    "    plt.plot(df.age_yrs[df.celltype==c], df.survival_days[df.celltype==c], \"o\", alpha=0.5)\n",
    "    \n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"survival days\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data for modeling\n",
    "\n",
    "Let's get everything onto a common scale (note- we could also just choose different priors for each if we wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xcols = treatment, small cell, adeno, large, karnofsky, months from diagnosis, age, prior therapy\n",
    "X = np.concatenate([\n",
    "    df.treatment.values.reshape(-1,1)-1, # treatment\n",
    "    celltype.values[:,1:], # 3 binary columns for cell type\n",
    "    df.karnofsky.values.reshape(-1,1)/100, # normalized Karnofsky score\n",
    "    np.log10(df.months_from_diagnosis.values.reshape(-1,1)), # months from diagnosis on a log scale\n",
    "    df.age_yrs.values.reshape(-1,1)/80, # rescaled age\n",
    "    df.prior_therapy.values.reshape(-1,1)/10 # \n",
    "], 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = df.survival_days.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# censored/uncensored indicator\n",
    "uncensored = df.status == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the model\n",
    "\n",
    "This should look (mostly) like a standard linear regression with a bit of pizzazz. Notably:\n",
    "\n",
    "* separate uncensored and censored inputs (though the coefficients are shared)\n",
    "* PMFs and CDFs of the Weibull distribution added to the `target`\n",
    "* a Gamma prior over the Weibull shape distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code = \"\"\"\n",
    "data {\n",
    "  // number of covariates\n",
    "  int K;\n",
    "  \n",
    "  // uncensored inputs\n",
    "  int N_u;\n",
    "  vector[N_u] y_u;\n",
    "  matrix[N_u, K] X_u;\n",
    "  \n",
    "  // censored inputs\n",
    "  int N_c;\n",
    "  vector[N_c] y_c;\n",
    "  matrix[N_c, K] X_c;\n",
    "  \n",
    "  // priors\n",
    "  vector[K] beta_scale;\n",
    "  real intercept_scale;\n",
    "  \n",
    "  // gamma prior over Weibull shape param\n",
    "  real gamma_alpha;\n",
    "  real gamma_beta;\n",
    "}\n",
    "parameters {\n",
    "  // regression coefficients for each covariate\n",
    "  vector[K] beta;\n",
    "  // regression intercept\n",
    "  real intercept;\n",
    "  // Weibull distribution shape parameter\n",
    "  real<lower=0> shape;\n",
    "}\n",
    "model{\n",
    "  // shape parameter prior\n",
    "  shape ~ gamma(gamma_alpha, gamma_beta);\n",
    "  \n",
    "  // priors for the regression coefficients\n",
    "  beta ~ normal(0, beta_scale);\n",
    "  intercept ~ normal(0, intercept_scale);\n",
    "  \n",
    "  // likelihood: log-PDF for uncensored data and log-CDF for censored\n",
    "  target += weibull_lpdf(y_u| shape, exp(intercept + X_u*beta));\n",
    "  target += weibull_lccdf(y_c| shape, exp(intercept + X_c*beta));\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = pystan.StanModel(model_code=model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "K = X.shape[1]\n",
    "gamma_alpha = 10\n",
    "gamma_beta = 10\n",
    "data = {\"y_u\":y[uncensored],\n",
    "        \"X_u\":X[uncensored],\n",
    "        \"N_u\":X[uncensored].shape[0],\n",
    "        \"y_c\":y[~uncensored],\n",
    "        \"X_c\":X[~uncensored],\n",
    "        \"N_c\":X[~uncensored].shape[0],\n",
    "       \"K\":K,\n",
    "       \"beta_scale\":5*np.ones(K),\n",
    "       \"intercept_scale\":10,\n",
    "       \"gamma_alpha\":gamma_alpha,\n",
    "       \"gamma_beta\":gamma_beta}\n",
    "\n",
    "fit = model.sampling(data=data, iter=2000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weibull shape parameter\n",
    "\n",
    "For this case, my naive expectation would be a shape parameter greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(7,5)\n",
    "plt.hist(np.random.gamma(gamma_alpha, 1/gamma_beta, size=len(traces[\"shape\"])), alpha=0.5, label=\"prior\")\n",
    "plt.hist(traces[\"shape\"], alpha=0.5, label=\"posterior\")\n",
    "plt.grid(True)\n",
    "ax = plt.axis()\n",
    "plt.vlines(1, -1e6, 1e6, linestyle=\"dashed\")\n",
    "plt.axis(ax)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Posterior estimate of shape parameter\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12,5)\n",
    "xcols = [\"treatment\", \"small cell\", \"adeno\", \"large\", \"karnofsky\", \"months\\nfrom\\ndiagnosis\", \n",
    "         \"age\", \"prior therapy\"]\n",
    "\n",
    "plt.violinplot(traces[\"beta\"])\n",
    "plt.xticks(np.arange(1,9), xcols)\n",
    "plt.grid(True)\n",
    "plt.hlines(0, -1, 9, linestyles=\"dashed\")\n",
    "plt.xlim(0, 9)\n",
    "plt.title(\"Regression coefficient posteriors\", fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the Karnofsky score is really strongly predictive- is it highly-correlated with our target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12,5)\n",
    "plt.plot(df.karnofsky, df.survival_days, \"o\", alpha=0.5)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Karnofsky score\", fontsize=14)\n",
    "plt.ylabel(\"survival days\", fontsize=14)\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictive distribution\n",
    "\n",
    "Comparing real with simulated data drawn from the PPD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = (traces[\"beta\"].dot(X.T) + np.expand_dims(traces[\"intercept\"],1))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12,10)\n",
    "j = 1\n",
    "for i in np.random.choice(np.arange(logits.shape[0]), size=9):\n",
    "    plt.subplot(3,3,j)\n",
    "    shape = traces[\"shape\"][i]\n",
    "    weibull = np.random.weibull(shape, size=logits.shape[1])\n",
    "    plt.plot(df.karnofsky, df.survival_days, \".\", alpha=0.5)\n",
    "    plt.plot(df.karnofsky, weibull*np.exp(logits[i,:]), \".\", alpha=0.5)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid(True);\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also look at summary stats on real and synthetic data broken out by one of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12,4)\n",
    "typenames = [\"squamous\", \"small cell\", \"adeno\", \"large\"]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    subset = df.celltype == i+1\n",
    "    med_days = np.median(df.survival_days[subset].values)\n",
    "    \n",
    "    N = subset.sum()\n",
    "    posterior_medians = [\n",
    "        np.median(np.random.weibull(traces[\"shape\"][j], size=N)*np.exp(logits[j,subset]))\n",
    "        for j in range(logits.shape[0])\n",
    "    ]\n",
    "    plt.hist(posterior_medians)\n",
    "    ax = plt.axis()\n",
    "    plt.vlines(med_days, -1e6,1e6, linestyles=\"dashed\")\n",
    "    plt.axis(ax)\n",
    "    xlim = plt.xlim()\n",
    "    plt.xlim(min(xlim[0], med_days-1), max(xlim[1], med_days+1))\n",
    "    plt.title(typenames[i])\n",
    "    plt.xlabel(\"median days survived\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(17,4)\n",
    "treatmentnames = [\"standard\", \"test\"]\n",
    "for i in range(2):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    subset = df.treatment == i+1\n",
    "    med_days = np.median(df.survival_days[subset].values)\n",
    "    \n",
    "    N = subset.sum()\n",
    "    posterior_medians = [\n",
    "        np.median(np.random.weibull(traces[\"shape\"][j], size=N)*np.exp(logits[j,subset]))\n",
    "        for j in range(logits.shape[0])\n",
    "    ]\n",
    "    plt.hist(posterior_medians)\n",
    "    ax = plt.axis()\n",
    "    plt.vlines(med_days, -1e6,1e6, linestyles=\"dashed\")\n",
    "    plt.axis(ax)\n",
    "    xlim = plt.xlim()\n",
    "    plt.xlim(min(xlim[0], med_days-1), max(xlim[1], med_days+1))\n",
    "    plt.title(treatmentnames[i])\n",
    "    plt.xlabel(\"median days survived\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
